# -*- coding: utf-8 -*-
"""ia2mllvadsusr194_varundaslab1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bsk8JsBFwEe_FOe5Z17kt4vKa8IepOZ9

**Classification**
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from scipy.cluster.hierarchy import dendrogram, linkage
from scipy.cluster.hierarchy import fcluster
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler,LabelEncoder
le=LabelEncoder()
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report,f1_score
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from imblearn.over_sampling import SMOTE

import warnings
warnings.filterwarnings("ignore")

df=pd.read_csv("/content/winequality-red.csv")

df.shape

df.info()

df.describe(include='all')

df.rename(columns={'Life expectancy ':'Life_expectancy'}, inplace=True)
df.rename(columns={'Adult Mortality':'Adult_Mortality'}, inplace=True)
df.rename(columns={' BMI ':'BMI'}, inplace=True)

df.isnull().sum()

df.duplicated().sum()

"""**UNIVARIATE ANALYSIS**"""

for column in df.select_dtypes(include={'float64','int64'}).columns:
  plt.figure(figsize=(10,5))
  sns.histplot(df[column])
  plt.title(f'Histogram of {column}')
  plt.xlabel(column)
  plt.ylabel('Frequency')
  plt.show()

for column in df.select_dtypes(include=['object']).columns:
  plt.figure(figsize=(10,5))
  df[column].value_counts().plot(kind='bar')
  plt.title(f'Bar chart of {column}')
  plt.xlabel(column)
  plt.ylabel('Count')
  plt.show()

"""**Bi variant**"""

#scatter plot
numerical_columns=df.select_dtypes(include={'float64','int64'}).columns
for i in range(len(numerical_columns)):
    for j in range(i + 1, len(numerical_columns)):
        plt.figure(figsize=(10, 6))
        sns.scatterplot(data=df, x=numerical_columns[i], y=numerical_columns[j])
        plt.title(f'Scatter Plot between {numerical_columns[i]} and {numerical_columns[j]}')
        plt.show()

#heatmap
#correlation matrix
numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
correlation_matrix = df[numerical_columns].corr()
print("Correlation matrix:\n", correlation_matrix)

#heatmap
plt.figure(figsize=(14, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Heatmap of Correlation Matrix')
plt.show()

df.isnull().sum()

df['fixed acidity']=df['fixed acidity'].fillna(df['fixed acidity'].median())
df['volatile acidity']=df['volatile acidity'].fillna(df['volatile acidity'].median())
df['citric acid']=df['citric acid'].fillna(df['citric acid'].median())
df['residual sugar']=df['residual sugar'].fillna(df['residual sugar'].median())
df['chlorides']=df['chlorides'].fillna(df['chlorides'].median())
df['free sulfur dioxide']=df['free sulfur dioxide'].fillna(df['free sulfur dioxide'].median())
df['sulphates']=df['sulphates'].fillna(df['sulphates'].median())

df.duplicated().sum()

#drop duplicates
df.drop_duplicates(inplace=True)

#drop column
#df.drop(columns=[''], inplace=True)

#Outlier boxplot
# Identify numerical columns by data type
numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns

# Create a box plot for each numerical column
for column in numerical_columns:
    plt.figure(figsize=(10, 6))  # Set the figure size for better readability
    sns.boxplot(x=df[column])
    plt.title(f'Box Plot of {column}')
    plt.xlabel(column)
    plt.show()

#Outlier detection
q1 = np.quantile(df["number_of_weekend_nights"] , 0.25)
q3 = np.quantile(df["number_of_weekend_nights"] , 0.75)
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr
print("Q1:", q1)
print("Q3:", q3)
print("IQR:", iqr)
print("Lower Bound (Outlier):", lower_bound)
print("Upper Bound (Outlier):", upper_bound)
# Identify outliers
outliers = [i for i in df["number_of_weekend_nights"] if i < lower_bound or i > upper_bound]
print("Outliers:", outliers)

"""**Model**"""

df.head()

X = df.drop(columns=['quality'])
y = df['quality']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler=MinMaxScaler()
X_train=pd.DataFrame(scaler.fit_transform(X_train[list(X.columns)]),
                                    columns=X.columns)
X_test=pd.DataFrame(scaler.transform(X_test[list(X.columns)]),
                                    columns=X.columns)

# Apply SMOTE to handle class imbalance
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Train a RF classifier
clf = RandomForestClassifier(random_state=42)
clf.fit(X_train_resampled, y_train_resampled)

y_pred = clf.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1_score=f1_score(y_test, y_pred)

print("Accuracy:", round(accuracy * 100, 2), "%")
print("Precision:", round(precision * 100, 2), "%")
print("Recall:", round(recall * 100, 2), "%")
print("F1_score:", round(f1_score * 100, 2), "%")

# Generate a classification report
print(classification_report(y_test, y_pred))

# Generate a confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, cmap="YlGnBu", fmt="d", cbar=False)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

