# -*- coding: utf-8 -*-
"""ia2mllvadsusr194_varundaslab2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fdp9W-pfIVm9u_7pqM62khFN_phXg-30

**Clustring**
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from scipy.cluster.hierarchy import dendrogram, linkage
from scipy.cluster.hierarchy import fcluster
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler,LabelEncoder
le=LabelEncoder()
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report,f1_score
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from imblearn.over_sampling import SMOTE

import warnings
warnings.filterwarnings("ignore")

df1= pd.read_csv("/content/Mall_Customers.csv")
df1.head()

df1.describe(include='all').T

df1.info()

df1.duplicated().sum()

sns.heatmap(df1.select_dtypes(include = ['int64','float64']).corr(),annot=True)

df1.select_dtypes(include = ['int64','float64']).corr()

for column in df1.select_dtypes(include=['float64','int64']):
  sns.boxplot(df1[[column]])

df1.dtypes

df1['Gender']=le.fit_transform(df1['Gender'])

km = KMeans(n_clusters=3)
y_pred = km.fit_predict(df1[['Gender','Spending Score (1-100)']])

df1['Spending Score (1-100)'] = y_pred

df2 = df1[df1['Spending Score (1-100)'] == 0]
df3 = df1[df1['Spending Score (1-100)'] == 1]
df4 = df1[df1['Spending Score (1-100)'] == 2]


plt.scatter(df2.Gender,df2['Spending Score (1-100)'],color='green')
plt.scatter(df3.Gender,df3['Spending Score (1-100)'],color='blue')
plt.scatter(df4.Gender,df4['Spending Score (1-100)'],color='black')


plt.scatter(km.cluster_centers_[:,0],km.cluster_centers_[:,1],color='red',marker='*',label='centroid')
plt.xlabel('Gender')
plt.ylabel('Spending Score (1-100)')
plt.legend()

k_range = range(1,10)
sse = []
for k in k_range:
  km = KMeans(n_clusters=k)
  km.fit(df1[['Gender','Spending Score (1-100)']])
  sse.append(km.inertia_)

plt.xlabel('Clusters')
plt.ylabel('SSE value')
plt.plot(k_range,sse,marker='.')

print("Inertia:", km.inertia_)

km = KMeans(n_clusters=2)
y_pred = km.fit_predict(df1[['Gender','Spending Score (1-100)']])

df1['Spending Score (1-100)'] = y_pred

df2 = df1[df1['Spending Score (1-100)'] == 0]
df3 = df1[df1['Spending Score (1-100)'] == 1]
#df4 = df1[df1['Spending Score (1-100)'] == 2]


plt.scatter(df2.Gender,df2['Spending Score (1-100)'],color='green')
plt.scatter(df3.Gender,df3['Spending Score (1-100)'],color='blue')
#plt.scatter(df4.Gender,df4['Spending Score (1-100)'],color='black')


plt.scatter(km.cluster_centers_[:,0],km.cluster_centers_[:,1],color='red',marker='*',label='centroid')
plt.xlabel('Gender')
plt.ylabel('Spending Score (1-100)')
plt.legend()

print("Inertia:", km.inertia_)

